### Title: Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer (Security'20)

#### Summary

Fuzzing has been applied to multiple software to detect bugs, including JavaScript (JS) engines. Previous JS engine fuzzers usually use mutational or grammar-generative methods to create inputs. These methods can generate syntactically- and semantically- correct JS test cases,  but do not consider the relationship between the code fragments and likelihood for the input to trigger bugs. The paper conducts a preliminary study on existing CVEs, regression tests, and PoC exploits and observes that 1) many JS engine vulnerabilities come from the same source code files and 2) when parsing the JS code into code fragment of AST subtrees, over 95% fragments between regression tests and PoC exploits are syntactically overlap. Based on the observation, the paper proposes to train an NNLM model to capture the syntactic and semantic relationships among code fragments from regression tests, into a tool, Montage. In detail, Montage consists of three phrases.  First, Montage parses the JS code from regression tests, PoC exploits, etc. into a sequence of code fragments, which are AST subtrees with a depth of one. The identifiers, e.g., variables and functions, are renamed to escape the influence and to better identify the syntactic and semantic relationships.  The code fragment sequences are designed to retail the syntactic and semantic relationships, and are used as instances of training data. Second, given existing code fragments as the context, the paper trains an LSTM model to predict the next fragment and prioritize those with the same type as the real fragment. Third, the trained model is used to generate JS code for testing. Based on a seed AST from a regression test, Montage first randomly prunes one subtree of it and lets the LSTM model start predicting the next several sequences of code fragments. In each prediction, LSTM model provides $ k_{top}$ suggested code fragments and Montage randomly selects one and appends it to the context code fragments. The prediction is executed at most $f_{max}$ times, which is empirically set to be 100 here.  Due to the dynamic nature of JS language, generated tests can still contain reference errors because of undefined identifiers. A static type inference is applied to resolve such issues.

Montage is thoroughly evaluated. The demonstration of perplexity and type error on the LSTM model suggests the epoch of 70 shall be the optimal points for the model, which is then used for other evaluations. About the parameter of $ k_{top}$, the authors generate 100,000 JS tests for different  values, and check how many tests can be executed without ECMAScript standard errors. The evaluation shows that when $ k_{top}$ is set to 64, Montage is capable to find more unique crashes.  Thus 64 is chosen as its desired value. Montage is compared with the state-of-the-art fuzzers including CodeAlchemist, jsfunfuzz, and IFuzzer on existing CVE vulnerabilities. After a total of 31,680 CPU hours of experiments,  in the release build of JS engines, Montage finds the largest number of CVEs, whereas jsfunfuzz still discovers more unique crashes; in the debug build, Montage outperforms all others in finding both unique crashes and CVEs. Further comparison with other language models, i.e., random fragment selection and Markov model-driven fragment selection, shows that Montage's code fragment sequence model achieves the best performance among the others. Applying Montage to the latest version of JS engines for 1.5 months reveals 37 unique bugs, three of which are security-related. The evaluation sufficiently supports the reasonable design and high efficacy of Montage.